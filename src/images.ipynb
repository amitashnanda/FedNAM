{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "5XJ216YsR8KK",
        "outputId": "534b4937-4225-4feb-c189-edec4c90b114"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "# Define the transformation for the image dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define a simple CNN model for image classification\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Train the model on each client's data and save the weights\n",
        "epochs = 20\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, trainloader, epochs, criterion):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = SimpleCNN()\n",
        "trained_model = train_model(model, trainloader, epochs, criterion)\n",
        "\n",
        "# Function to get the top 30% contributing pixels\n",
        "def get_top_contributing_pixels(model, data, percentage=0.3):\n",
        "    model.eval()\n",
        "    data.requires_grad_()\n",
        "    output = model(data)\n",
        "    pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "    model.zero_grad()\n",
        "    output[0, pred_class].backward()\n",
        "    grad = data.grad.abs().squeeze().detach().numpy()\n",
        "\n",
        "    # Flatten the gradient array and get the threshold value\n",
        "    flattened_grad = grad.flatten()\n",
        "    threshold = np.percentile(flattened_grad, 100 - percentage * 100)\n",
        "\n",
        "    # Create a mask of the top contributing pixels\n",
        "    top_pixels_mask = grad >= threshold\n",
        "\n",
        "    return top_pixels_mask\n",
        "\n",
        "# Get a test image\n",
        "test_images, _ = next(iter(testloader))\n",
        "test_image = test_images[0].unsqueeze(0)\n",
        "\n",
        "# Get the top 30% contributing pixels\n",
        "top_pixels_mask = get_top_contributing_pixels(trained_model, test_image)\n",
        "highlighted_image = test_image.squeeze().detach().numpy()  # tensor.detach().numpy()\n",
        "\n",
        "# Convert the mask to coordinates\n",
        "mask_2d = top_pixels_mask\n",
        "highlighted_image[mask_2d == 0] = 0  # Mask non-top pixels\n",
        "\n",
        "# Plot the original and highlighted image\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(test_image.squeeze().detach().numpy(), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('Original_image.png', dpi=600)\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Highlighted Image\")\n",
        "plt.imshow(highlighted_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.savefig('Highlighted_Image.png', dpi=600)\n",
        "plt.show()\n",
        "\n",
        "# Configuration class\n",
        "class Config:\n",
        "    def __init__(self, dropout=0.5, learning_rate=0.001, num_epochs=50, batch_size=32):\n",
        "        self.dropout = dropout\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "# Base Model class (assuming you have this implemented)\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, config, name):\n",
        "        super(Model, self).__init__()\n",
        "        self.config = config\n",
        "        self.name = name\n",
        "\n",
        "# FeatureNN class (assuming you have this implemented)\n",
        "class FeatureNN(nn.Module):\n",
        "    def __init__(self, config, name, input_shape, num_units, feature_num):\n",
        "        super(FeatureNN, self).__init__()\n",
        "        self.config = config\n",
        "        self.name = name\n",
        "        self.input_shape = input_shape\n",
        "        self.num_units = num_units\n",
        "        self.feature_num = feature_num\n",
        "        self.fc = nn.Linear(input_shape, num_units)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "# NAM model definition\n",
        "class NAM(Model):\n",
        "    def __init__(self, config, name, *, num_inputs: int, num_units: int) -> None:\n",
        "        super(NAM, self).__init__(config, name)\n",
        "        self._num_inputs = num_inputs\n",
        "        self.dropout = nn.Dropout(p=self.config.dropout)\n",
        "\n",
        "        if isinstance(num_units, list):\n",
        "            assert len(num_units) == num_inputs\n",
        "            self._num_units = num_units\n",
        "        elif isinstance(num_units, int):\n",
        "            self._num_units = [num_units for _ in range(self._num_inputs)]\n",
        "\n",
        "        self.feature_nns = nn.ModuleList([\n",
        "            FeatureNN(config=config, name=f'FeatureNN_{i}', input_shape=1, num_units=self._num_units[i], feature_num=i)\n",
        "            for i in range(num_inputs)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Linear(sum(self._num_units), 10)  # 10 classes for MNIST dataset\n",
        "        self._bias = torch.nn.Parameter(data=torch.zeros(1))\n",
        "\n",
        "    def calc_outputs(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        return [self.feature_nns[i](inputs[:, i:i+1]) for i in range(self._num_inputs)]\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
        "        individual_outputs = self.calc_outputs(inputs)\n",
        "        conc_out = torch.cat(individual_outputs, dim=-1)\n",
        "        dropout_out = self.dropout(conc_out)\n",
        "        out = self.output_layer(dropout_out)\n",
        "        return out, dropout_out\n",
        "\n",
        "    def print_model_equation(self, feature_names):\n",
        "        equation_terms = []\n",
        "        feature_contributions = {}\n",
        "        for i, fnn in enumerate(self.feature_nns):\n",
        "            coefficients = fnn.fc.weight.data.flatten().tolist()\n",
        "            intercepts = fnn.fc.bias.data.tolist()\n",
        "            term = \" + \".join([f\"({coeff:.3f} * x_{feature_names[i]} + {intercept:.3f})\" for coeff, intercept in zip(coefficients, intercepts)])\n",
        "            equation_terms.append(term)\n",
        "            feature_contributions[feature_names[i]] = sum(abs(c) for c in coefficients)\n",
        "        equation = \" + \".join(equation_terms) + f\" + bias ({self._bias.item():.3f})\"\n",
        "        print(f\"Model Equation: y = {equation}\")\n",
        "\n",
        "        # Determine feature interpretability based on coefficients\n",
        "        interpretability = sorted(feature_contributions.items(), key=lambda x: x[1], reverse=True)\n",
        "        print(\"\\nFeature Contributions:\")\n",
        "        for feature, contribution in interpretability:\n",
        "            print(f\"{feature}: {contribution:.3f}\")\n",
        "\n",
        "        return interpretability[0][0]  # Return the feature with the highest contribution\n",
        "\n",
        "# Define the config\n",
        "config = Config(dropout=0.5, learning_rate=0.001, num_epochs=50, batch_size=32)\n",
        "\n",
        "# Instantiate the NAM model\n",
        "num_inputs = 28 * 28  # Number of features for MNIST images\n",
        "num_units = 10  # Number of units in the hidden layer\n",
        "nam_model = NAM(config=config, name='NAM_Model', num_inputs=num_inputs, num_units=num_units)\n",
        "\n",
        "# Training function for NAM model\n",
        "def train_nam_model(model, trainloader, config):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "    model.train()\n",
        "    for epoch in range(config.num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(inputs.view(inputs.size(0), -1))  # Flatten the inputs\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{config.num_epochs}], Loss: {running_loss / len(trainloader):.4f}')\n",
        "    return model\n",
        "\n",
        "# Train the NAM model\n",
        "trained_nam_model = train_nam_model(nam_model, trainloader, config)\n",
        "\n",
        "# Evaluate the NAM model\n",
        "def evaluate_nam_model(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            outputs, _ = model(inputs.view(inputs.size(0), -1))  # Flatten the inputs\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "evaluate_nam_model(trained_nam_model, testloader)\n",
        "\n",
        "# Print the model equation and get the most contributing feature\n",
        "feature_names = [f'pixel_{i}' for i in range(num_inputs)]\n",
        "most_contributing_feature = trained_nam_model.print_model_equation(feature_names)\n",
        "print(f\"\\nMost contributing feature: {most_contributing_feature}\")\n"
      ]
    }
  ]
}